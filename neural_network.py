# -*- coding: utf-8 -*-
"""neural_network.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1flU1bsYCYjU3ViJd3tg1BnflQV5j5OX2
"""

import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
hospital_data = pd.read_excel('/content/drive/My Drive/Forecasting model/COVID_case_report_final.xlsx')

data = hospital_data

data =hospital_data.drop(['City','Total Laboratory-confirmed case',	'difference to the previous day','hospitalized','Deceased',
                     'Recover-A','Reported the last 7 days','Rhineland-Palatinate',	'+USAFD',	'<20 years','20-59 years-E','â‰¥ 60 years'],axis=1)

data.columns = ["currentcases","Date"]
data

data.dropna(inplace=True)
len(data)

import numpy as np
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.preprocessing import MinMaxScaler

#preprocess and clean the data
data['Date'] = pd.to_datetime(data['Date'])
data.set_index('Date', inplace=True)

# Scale the data between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Define the number of past days to use as input for prediction
look_back = 7

# Split the data into training and testing sets
train_size = int(len(scaled_data) * 0.7)
test_size = len(scaled_data) - train_size
train_data, test_data = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]

# Convert the data into sequences
def create_sequences(data, look_back):
    X, y = [], []
    for i in range(len(data)-look_back):
        X.append(data[i:(i+look_back), :])
        y.append([data[(i+look_back), 0]])
    return np.array(X), np.array(y)

X_train, y_train = create_sequences(train_data, look_back)
X_test, y_test = create_sequences(test_data, look_back)

# Define the neural network model
model = Sequential()
model.add(Dense(units=64, input_dim=X_train.shape[1]*X_train.shape[2], activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(units=32, activation='relu'))
model.add(Dropout(0.2))
model.add(Dense(units=1))

model.compile(optimizer='adam', loss='mean_squared_error')

# Train the neural network model
model.fit(X_train.reshape(X_train.shape[0], -1), y_train, epochs=100, batch_size=32)

# Make predictions using the neural network model
train_predict = model.predict(X_train.reshape(X_train.shape[0], -1))
test_predict = model.predict(X_test.reshape(X_test.shape[0], -1))

# Evaluate the neural network model
train_score = model.evaluate(X_train.reshape(X_train.shape[0], -1), y_train, verbose=0)
print('Train Score: %.2f MSE (%.2f RMSE)' % (train_score, np.sqrt(train_score)))
test_score = model.evaluate(X_test.reshape(X_test.shape[0], -1), y_test, verbose=0)
print('Test Score: %.2f MSE (%.2f RMSE)' % (test_score, np.sqrt(test_score)))

# Make predictions using the neural network model
train_predict = model.predict(X_train.reshape(X_train.shape[0], -1))
test_predict = model.predict(X_test.reshape(X_test.shape[0], -1))

# Inverse the scaling to get actual values
train_predict = scaler.inverse_transform(np.concatenate((X_train[:, -1, 0].reshape(-1, 1), train_predict), axis=1))[:, -1]
y_train = scaler.inverse_transform([np.concatenate((X_train[:, -1, 0].reshape(-1, 1), y_train.reshape(-1, 1)), axis=1)[:, -1]])
test_predict = scaler.inverse_transform(np.concatenate((X_test[:, -1, 0].reshape(-1, 1), test_predict), axis=1))[:, -1]
y_test = scaler.inverse_transform([np.concatenate((X_test[:, -1, 0].reshape(-1, 1), y_test.reshape(-1, 1)), axis=1)[:, -1]])

new_test = np.array(y_test).flatten()
new_predict = np.array(test_predict).flatten()
predictions = pd.DataFrame({'Date': data.index[look_back+train_size:], 'Actual': new_test, 'Predicted': new_predict})

# Set the date column as the index
predictions.set_index('Date', inplace=True)

# Print the dataframe
predictions[:7]

predictions.plot(figsize=(12,6))

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Example continuous actual and predicted values
y_true = np.array(predictions['Actual'])
y_pred = np.array(predictions['Predicted'])

# Calculate mean squared error (MSE)
mse = mean_squared_error(y_true, y_pred)

# Calculate mean absolute error (MAE)
mae = mean_absolute_error(y_true, y_pred)

# Calculate R-squared
r2 = r2_score(y_true, y_pred)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared:", r2)

predictions.describe()

data.describe()

