# -*- coding: utf-8 -*-
"""RandomForest_updated.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ygV57OAqdy4ZMBhY5Xa-kFayvrC-TRak
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
data = pd.read_excel('/content/drive/My Drive/Forecasting model/COVID_case_report_final.xlsx')
data.columns=['Location','TotalCase','Difference_to_the_previous_day','Hospitalized','Deceased','Recover','Current_Cases','Reported_last_7_days','Rhineland-Palatinate'
	,'+USAFD','<20 years','20-59 years','â‰¥ 60 years','Date']

data

import pandas as pd
import numpy as np
from sklearn.preprocessing import OneHotEncoder
# Remove duplicates
data.drop_duplicates(inplace=True)
# Remove rows with missing values
data.dropna(inplace=True)
# Convert data types
data['Date'] = pd.to_datetime(data['Date'])
data['TotalCase'] = data['TotalCase'].astype(float)
# Replace invalid values with NaN
data.replace('--*', np.nan, inplace=True)
# Drop irrelevant columns
data.drop(['Rhineland-Palatinate','+USAFD'], axis=1, inplace=True)
# Rename columns
data.columns = ['Location', 'Total', 'Diff_prev_day', 'Hospitalization', 'Deceased', 'Recovered', 'Current_cases','Reported_last_7_days', '<20_years', '20-59_years', '>=60_years','Date']
# Clean the Location column
data['Location'] = data['Location'].str.replace(' +', ' ',regex=True)
data['Location'] = data['Location'].str.strip()
# Convert to categorical variable
data['Location'] = data['Location'].astype('category')
# Use one-hot encoding to convert the location column to numerical variables
encoder = OneHotEncoder()
loc_encoded = encoder.fit_transform(data[['Location']])
location_data = pd.DataFrame(loc_encoded.toarray(), columns=encoder.get_feature_names_out(['Location']))
# Concatenate the original data with the one-hot encoded location data
data = pd.concat([data, location_data], axis=1)
data.drop(['Location'], axis=1, inplace=True)
# Set Date as the index
data.set_index('Date', inplace=True)

data = data.dropna()

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Define features and target
features = ['Diff_prev_day', 'Hospitalization', 'Deceased', 'Recovered', 'Current_cases','Reported_last_7_days', '<20_years', '20-59_years', '>=60_years']
target = 'Total'

# Split data into training and test sets
train_data, test_data, train_target, test_target = train_test_split(data[features], data[target], test_size=0.2, random_state=42)

# Initialize random forest model with default parameters
forest_model = RandomForestRegressor(n_estimators=300, max_depth=5, random_state=42)

# Train model on training data
forest_model.fit(train_data, train_target)

# Make predictions on test data
predictions = forest_model.predict(test_data)

# Evaluate model performance
mse = mean_squared_error(test_target, predictions)
print(f'Mean Squared Error: {mse}')

variance = np.var(test_target - predictions)
variance

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score

mae = mean_absolute_error(test_target,predictions)
rmse = np.sqrt(mse)
r2 = r2_score(test_target,predictions)

print(f'Mean Absolute Error: {mae}')
print(f'Root Mean Squared Error: {rmse}')
print(f'r squared: {r2}')

"""In the given case, the difference between the variance and MSE is very small, which suggests that the model is performing fairly well in terms of accuracy and consistency. However, we cannot conclude the model's performance solely based on these two metrics. We also need to consider other evaluation metrics and analyze the results in the context of the problem being solved.
Based on the metrics you provided, the model seems to perform well. The Mean Absolute Error (MAE) of 728.50 and Root Mean Squared Error (RMSE) of 1037.89 are relatively small compared to the mean of the target variable and indicate that the model's predictions are on average close to the actual values.

The R-squared value of 0.9975 indicates that the model explains a high proportion of the variance in the target variable and is a good fit for the data.
"""

data.describe()

import matplotlib.pyplot as plt
important_feature = forest_model.feature_importances_

# Plot feature importances
plt.bar(features, important_feature,color="Red")
plt.xticks(rotation=90)
plt.xlabel('Feature')
plt.ylabel('Importance')
plt.title('Feature Importances')
plt.show()

output = pd.DataFrame({'Actual_value':test_target,'Predicted_value':predictions})
output

plt.plot(output)

"""This indicates a relatively large difference between the actual and predicted value."""

new_color = output['Actual_value']-output['Predicted_value']
new_color2 = ['red' if x > 0 else 'green' for x in new_color]

plt.scatter(output['Actual_value'], output['Predicted_value'], c = new_color2, alpha = 0.5)
plt.scatter([],[], c='red', alpha=0.5, label='Overprediction')
plt.scatter([],[], c='green', alpha=0.5, label='Underprediction')
plt.xlabel('Actual')
plt.ylabel('Predicted')
plt.title('Actual vs Predicted Values')
plt.legend(loc='upper left')
plt.show()

import seaborn as sn
sn.set_style("whitegrid")
plt.hist(output["Actual_value"],bins=20)
plt.hist(output['Predicted_value'],bins=20)
plt.show()

