# -*- coding: utf-8 -*-
"""timeseries2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1w57JRoFPPydTsBdelr9J1nC-elbc_xWD
"""

import pandas as pd
import numpy as np
import matplotlib as plt

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

dataset = pd.read_excel('/content/drive/My Drive/Forecasting model/COVID_case_report_final.xlsx')

dataset

data = dataset.drop(['City','Total Laboratory-confirmed case',	'difference to the previous day','hospitalized','Deceased',
                     'Recover-A', 'Reported the last 7 days','Rhineland-Palatinate',	'+USAFD',	'<20 years','20-59 years-E','â‰¥ 60 years'],axis=1)

data = data.dropna()
data.columns = ["current_cases","Date"]
data

data.dtypes

# Convert date column to datetime
data['Date'] = pd.to_datetime(data['Date'])

# Set date column as index
data.set_index('Date', inplace=True)

data.plot(figsize=(12,6))

from statsmodels.tsa.seasonal import seasonal_decompose

plt.rcParams["figure.figsize"] = (15,6)
output = seasonal_decompose(data['current_cases'],period=7)
output.plot()

# Remove the rows with missing values
data.dropna(inplace=True)

import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler


# Scale the data between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Define the number of past days to use as input for prediction
look_back = 7

# Split the data into training and testing sets
train_size = int(len(scaled_data) * 0.7)
test_size = len(scaled_data) - train_size
train_data, test_data = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]

# Convert the data into sequences
def create_sequences(data, look_back):
    X, y = [], []
    for i in range(len(data)-look_back):
        X.append(data[i:(i+look_back), :])
        y.append([data[(i+look_back)]])
    return np.array(X), np.array(y)

X_train, y_train = create_sequences(train_data, look_back)
X_test, y_test = create_sequences(test_data, look_back)

# Reshape the input data for LSTM model
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))

# Define the LSTM model
model = Sequential()
model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dense(units=1))
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model
model.fit(X_train, y_train, epochs=100, batch_size=32)

# Evaluate the LSTM model
train_score = model.evaluate(X_train, y_train, verbose=0)
print('Train Score: %.2f MSE (%.2f RMSE)' % (train_score, np.sqrt(train_score)))
test_score = model.evaluate(X_test, y_test, verbose=0)
print('Test Score: %.2f MSE (%.2f RMSE)' % (test_score, np.sqrt(test_score)))


# Make predictions using the LSTM model

train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Inverse the scaling to get actual values
train_predict = scaler.inverse_transform(np.concatenate((X_train[:, -1, 0].reshape(-1, 1), train_predict), axis=1))[:, -1]
y_train = scaler.inverse_transform([np.concatenate((X_train[:, -1, 0].reshape(-1, 1), y_train.reshape(-1, 1)), axis=1)[:, -1]])
test_predict = scaler.inverse_transform(np.concatenate((X_test[:, -1, 0].reshape(-1, 1), test_predict), axis=1))[:, -1]
y_test = scaler.inverse_transform([np.concatenate((X_test[:, -1, 0].reshape(-1, 1), y_test.reshape(-1, 1)), axis=1)[:, -1]])

# Remove extra dimension from y_test and test_predict arrays
y_test = np.squeeze(y_test)
test_predict = np.squeeze(test_predict)

new_test = np.array(y_test)
new_predict = np.array(test_predict)
predictions_df = pd.DataFrame({'Date': data.index[look_back+train_size:], 'Actual': new_test, 'Predicted': new_predict})

# Set the date column as the index
predictions_df.set_index('Date', inplace=True)

# Print the dataframe
predictions_df[0:7]

predictions_df.plot(figsize=(12,6))

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Example continuous actual and predicted values
y_true = np.array(predictions_df['Actual'])
y_pred = np.array(predictions_df['Predicted'])

# Calculate mean squared error (MSE)
mse = mean_squared_error(y_true, y_pred)

# Calculate mean absolute error (MAE)
mae = mean_absolute_error(y_true, y_pred)

# Calculate R-squared
r2 = r2_score(y_true, y_pred)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared:", r2)

predictions_df.describe()

data.describe()