# -*- coding: utf-8 -*-
"""TimeseriesSecondpart.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JNZCY8KYh8IjVHO2_IVkH6P2gUwhqWqN
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
hospital_data = pd.read_excel('/content/drive/My Drive/Forecasting model/hospital.xlsx')

#data =hospital_data.drop(['City','Total Laboratory-confirmed case',	'difference to the previous day','current cases-B','Deceased',
                     'Recover-A','Reported the last 7 days','Rhineland-Palatinate',	'+USAFD',	'<20 years','20-59 years-E','â‰¥ 60 years'],axis=1)

data = hospital_data

data.columns = ["Date","7-day-incident"]
data

data.dropna(inplace=True)
len(data)

import numpy as np
from keras.models import Sequential
from keras.layers import LSTM, Dense
from sklearn.preprocessing import MinMaxScaler

# Convert the date column to a pandas datetime object
data['Date'] = pd.to_datetime(data['Date'])

# Set the date column as the index
data.set_index('Date', inplace=True)

# Remove the rows with missing values
data.dropna(inplace=True)

# Scale the data between 0 and 1
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data.values)

# Define the number of past days to use as input for prediction
look_back = 7

# Split the data into training and testing sets
train_size = int(len(scaled_data) * 0.7)
test_size = len(scaled_data) - train_size
train_data, test_data = scaled_data[0:train_size,:], scaled_data[train_size:len(scaled_data),:]

# Convert the data into sequences
def create_sequences(data, look_back):
    X, y = [], []
    for i in range(len(data)-look_back):
        X.append(data[i:(i+look_back), :])
        y.append([data[(i+look_back)]])
    return np.array(X), np.array(y)

X_train, y_train = create_sequences(train_data, look_back)
X_test, y_test = create_sequences(test_data, look_back)

# Reshape the input data for LSTM model
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], X_test.shape[2]))

# Define the LSTM model
model = Sequential()
model.add(LSTM(units=50, input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dense(units=1))

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error')

# Train the LSTM model with early stopping
history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))

# Evaluate the LSTM model
train_score = model.evaluate(X_train, y_train, verbose=0)
print('Train Score: %.2f MSE (%.2f RMSE)' % (train_score, np.sqrt(train_score)))
test_score = model.evaluate(X_test, y_test, verbose=0)
print('Test Score: %.2f MSE (%.2f RMSE)' % (test_score, np.sqrt(test_score)))

# Make predictions using the LSTM model
train_predict = model.predict(X_train)
test_predict = model.predict(X_test)

# Inverse the scaling to get actual values
train_predict = scaler.inverse_transform(np.concatenate((X_train[:, -1, 0].reshape(-1, 1), train_predict), axis=1))[:, -1]
y_train = scaler.inverse_transform([np.concatenate((X_train[:, -1, 0].reshape(-1, 1), y_train.reshape(-1, 1)), axis=1)[:, -1]])
test_predict = scaler.inverse_transform(np.concatenate((X_test[:, -1, 0].reshape(-1, 1), test_predict), axis=1))[:, -1]
y_test = scaler.inverse_transform([np.concatenate((X_test[:, -1, 0].reshape(-1, 1), y_test.reshape(-1, 1)), axis=1)[:, -1]])

# Remove extra dimension from y_test and test_predict arrays
y_test = np.squeeze(y_test)
test_predict = np.squeeze(test_predict)

new_test = np.array(y_test).flatten()
new_predict = np.array(test_predict).flatten()
predictions_df = pd.DataFrame({'Date': data.index[look_back+train_size:], 'Actual': new_test, 'Predicted': new_predict})

# Set the date column as the index
predictions_df.set_index('Date', inplace=True)

# Print the dataframe
predictions_df[:7]

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# Example continuous actual and predicted values
y_true = np.array(predictions_df['Actual'])
y_pred = np.array(predictions_df['Predicted'])

# Calculate mean squared error (MSE)
mse = mean_squared_error(y_true, y_pred)

# Calculate mean absolute error (MAE)
mae = mean_absolute_error(y_true, y_pred)

# Calculate R-squared
r2 = r2_score(y_true, y_pred)

print("Mean Squared Error:", mse)
print("Mean Absolute Error:", mae)
print("R-squared:", r2)

import numpy as np
from sklearn.metrics import make_scorer

def mean_absolute_percentage_error(y_true, y_pred):
    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100

mean_absolute_percentage_error(y_true, y_pred)

predictions_df.plot(figsize=(12,6))

predictions_df.describe()

data.describe()